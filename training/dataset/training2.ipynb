{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd5c0840-c707-4eb8-8145-045e1def1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03437fa8-3048-456e-a617-641ec063c09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1506 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./225,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34814265-bdfa-4aeb-9381-bc16d9dba67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in train_generator:\n",
    "    print(image_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2125c5d-3055-4cb3-819d-f3913e171689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 215 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./225,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'dataset/val',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f72d0915-2c53-4a19-8353-f8ce683a33c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 431 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./225,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/test',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93420aa4-a8ba-4a22-8e0b-d4bc3814fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 3\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    layers.Conv2D(32, kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62c4c4f5-60c0-416a-9b6c-327ed84fb981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183,747\n",
      "Trainable params: 183,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d07c5e58-a2d3-4b21-bd57-a886057f7119",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10d61a50-cda8-4d6c-86de-7f7525b564db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.0625"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1506/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7aca646-b707-4132-accb-f9311a5e8ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.71875"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "215/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "985768f0-e990-4860-99bc-cc203a0f1f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47/47 [==============================] - 76s 1s/step - loss: 0.8631 - accuracy: 0.5455 - val_loss: 0.7180 - val_accuracy: 0.7396\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 62s 1s/step - loss: 0.6324 - accuracy: 0.7422 - val_loss: 0.6668 - val_accuracy: 0.7292\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 54s 1s/step - loss: 0.3764 - accuracy: 0.8494 - val_loss: 0.2965 - val_accuracy: 0.8542\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 50s 1s/step - loss: 0.2678 - accuracy: 0.8955 - val_loss: 0.2877 - val_accuracy: 0.8698\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 47s 993ms/step - loss: 0.2691 - accuracy: 0.8915 - val_loss: 0.3338 - val_accuracy: 0.8542\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 46s 984ms/step - loss: 0.2266 - accuracy: 0.9152 - val_loss: 0.2266 - val_accuracy: 0.8906\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 44s 921ms/step - loss: 0.1725 - accuracy: 0.9315 - val_loss: 0.2971 - val_accuracy: 0.9115\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 43s 906ms/step - loss: 0.2019 - accuracy: 0.9233 - val_loss: 0.2162 - val_accuracy: 0.9323\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 43s 906ms/step - loss: 0.1413 - accuracy: 0.9423 - val_loss: 0.1869 - val_accuracy: 0.9219\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 45s 945ms/step - loss: 0.1255 - accuracy: 0.9484 - val_loss: 0.1465 - val_accuracy: 0.9323\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 43s 911ms/step - loss: 0.1393 - accuracy: 0.9478 - val_loss: 0.1888 - val_accuracy: 0.9062\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - 43s 911ms/step - loss: 0.1211 - accuracy: 0.9518 - val_loss: 0.3040 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - 45s 961ms/step - loss: 0.1408 - accuracy: 0.9498 - val_loss: 0.3370 - val_accuracy: 0.8802\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - 55s 1s/step - loss: 0.0868 - accuracy: 0.9695 - val_loss: 0.1274 - val_accuracy: 0.9427\n",
      "Epoch 15/20\n",
      "47/47 [==============================] - 75s 2s/step - loss: 0.1271 - accuracy: 0.9478 - val_loss: 0.1561 - val_accuracy: 0.9427\n",
      "Epoch 16/20\n",
      "47/47 [==============================] - 91s 2s/step - loss: 0.1243 - accuracy: 0.9552 - val_loss: 0.1528 - val_accuracy: 0.9219\n",
      "Epoch 17/20\n",
      "47/47 [==============================] - 82s 2s/step - loss: 0.0877 - accuracy: 0.9661 - val_loss: 0.1247 - val_accuracy: 0.9583\n",
      "Epoch 18/20\n",
      "47/47 [==============================] - 52s 1s/step - loss: 0.0639 - accuracy: 0.9729 - val_loss: 0.1375 - val_accuracy: 0.9479\n",
      "Epoch 19/20\n",
      "47/47 [==============================] - 58s 1s/step - loss: 0.0865 - accuracy: 0.9681 - val_loss: 0.1006 - val_accuracy: 0.9583\n",
      "Epoch 20/20\n",
      "47/47 [==============================] - 52s 1s/step - loss: 0.0695 - accuracy: 0.9756 - val_loss: 0.2687 - val_accuracy: 0.9115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e9dbbd67c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=47,\n",
    "    batch_size=32,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=6,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23d9b8f1-e257-433b-9a33-a553e5cb34ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 334ms/step - loss: 0.4160 - accuracy: 0.8840\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c5b6d9a-64cc-41f4-8ee4-f94cef32429c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4159635603427887, 0.8839907050132751]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97df8076-ba89-4169-b916-ebbfaf08a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../potatoes2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
